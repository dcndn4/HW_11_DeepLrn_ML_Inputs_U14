# -*- coding: utf-8 -*-
"""
Created on Mon Dec 20 12:42:48 2021

@author: CS_Knit_tinK_SC
"""

# LSTM Stock Predictor Using Closing Prices

#%%
#%%

# In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin closing prices to predict the 11th day closing price.

# You will need to:

#    Prepare the data for training and testing
#    Build and train a custom LSTM RNN
#    Evaluate the performance of the model

# Data Preparation

# In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.

# You will need to:

#    Use the window_data function to generate the X and y values for the model.
#    Split the data into 70% training and 30% testing
#    Apply the MinMaxScaler to the X and y values
#    Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:

# reshape((X_train.shape[0], X_train.shape[1], 1))


#%%

import numpy as np
import pandas as pd
import hvplot.pandas

#%%

# just for fun: to sketch out approximate run time for this notebook
import time  # for stopwatch and sleep
t1 = time.perf_counter()  # track execution time

#%%


# Set the random seed for reproducibility
# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model
from numpy.random import seed
seed(1)
from tensorflow import random
random.set_seed(2)

#%%

# Load the fear and greed sentiment data for Bitcoin
#filepath="C:/Users/CS_Knit_tinK_SC/Documents/My Data Sources/121821/aapl.csv"
file_btc_sntmnt="C:/Users/CS_Knit_tinK_SC/Documents/GitHub/HW_11_DeepLrn_ML_Inputs_U14/Starter_Code/btc_sentiment.csv"
df = pd.read_csv(file_btc_sntmnt, index_col="date", infer_datetime_format=True, parse_dates=True)
df = df.drop(columns="fng_classification")
print(df.head())

#%%

# Load the historical closing prices for Bitcoin
file_btc_hist="C:/Users/CS_Knit_tinK_SC/Documents/GitHub/HW_11_DeepLrn_ML_Inputs_U14/Starter_Code/btc_historic.csv"
df2 = pd.read_csv(file_btc_hist, index_col="Date", infer_datetime_format=True, parse_dates=True)['Close']
df2 = df2.sort_index()
print(df2.tail())

#%%

# Join the data into a single DataFrame
df = df.join(df2, how="inner")
print(df.tail())

#%%

print(df.head())

#%%

# This function accepts the column number for the features (X) and the target (y)
# It chunks the data up with a rolling window of Xt-n to predict Xt
# It returns a numpy array of X any y
def window_data(df, window, feature_col_number, target_col_number):
    X = []
    y = []
    for i in range(len(df) - window - 1):
        features = df.iloc[i:(i + window), feature_col_number]
        target = df.iloc[(i + window), target_col_number]
        X.append(features)
        y.append(target)
    return np.array(X), np.array(y).reshape(-1, 1)

#%%

# Predict Closing Prices using a 10 day window of previous closing prices
# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes
window_size = 10

# Column index 0 is the 'fng_value' column
# Column index 1 is the `Close` column
feature_column = 1
target_column = 1
X, y = window_data(df, window_size, feature_column, target_column)

#%%

# Use 70% of the data for training and the remaineder for testing
split = int(0.7 * len(X))

X_train = X[: split]
X_test = X[split:]

y_train = y[: split]
y_test = y[split:]
print(split)

#%%

from sklearn.preprocessing import MinMaxScaler
# Use the MinMaxScaler to scale data between 0 and 1.


# Create a MinMaxScaler object
scaler = MinMaxScaler()

# Fit the MinMaxScaler object with the features data X
scaler.fit(X_train)

# Scale the features training and testing sets
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Fit the MinMaxScaler object with the target data Y
scaler.fit(y_train)

# Scale the target training and testing sets
y_train = scaler.transform(y_train)
y_test = scaler.transform(y_test)

#%%

# Reshape the features for the model
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Print some sample data after reshaping the datasets
print (f"X_train sample values:\n{X_train[:3]} \n")
print (f"X_test sample values:\n{X_test[:3]}")

#%%

# Build and Train the LSTM RNN

# In this section, you will design a custom LSTM RNN and fit (train) it using the training data.

# You will need to:

#    Define the model architecture
#    Compile the model
#    Fit the model to the training data

# Hints:

# You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model.

#%%

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

#%%

# Define the LSTM RNN model.
model = Sequential()

number_units = 5  # equals the time window
dropout_fraction = 0.2

# Layer 1
model.add(LSTM(
    units=number_units,
    # except for final layer, each time we add a new LSTM layer, we must set return_sequences=True
    # it just lets Keras know to connect each layer
    return_sequences=True,
    input_shape=(X_train.shape[1], 1))
    )
model.add(Dropout(dropout_fraction))
# Layer 2
model.add(LSTM(units=number_units, return_sequences=True))
model.add(Dropout(dropout_fraction))
# Layer 3
model.add(LSTM(units=number_units))
model.add(Dropout(dropout_fraction))
# Output layer
model.add(Dense(1))

#%%

# Compile the model
model.compile(optimizer="adam", loss="mean_squared_error")

#%%

# Summarize the model
model.summary()

#%%

# Train the model
model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)

#%%

# Model PerformanceÂ¶

# In this section, you will evaluate the model using the test data.

# You will need to:

#    Evaluate the model using the X_test and y_test data.
#    Use the X_test data to make predictions
#    Create a DataFrame of Real (y_test) vs predicted values.
#    Plot the Real vs predicted values as a line chart

# Hints

# Remember to apply the inverse_transform function to the predicted and y_test values to recover the actual closing prices.
#%%

# Evaluate the model

model.evaluate(X_test, y_test)

#%%

# Make some predictions
predicted = model.predict(X_test)

#%%

# Recover the original prices instead of the scaled version
predicted_prices = scaler.inverse_transform(predicted)
real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))

#%%

print(predicted[0:10])
print(predicted_prices[0:10])

#%%

# Create a DataFrame of Real and Predicted values  (#01c kind of also)
stocks = pd.DataFrame({
    "Real": real_prices.ravel(),
    "Predicted": predicted_prices.ravel()
    }, index = df.index[-len(real_prices): ])
stocks.head()

#%%

# Plot the real vs predicted values as a line chart
stocks.plot(title='real vs predicted values')

#%%

# time estimate.. just to keep an eye on such aspects a little bit!
t2 = time.perf_counter()
execution_time = t2 - t1
print("execution time: " + str(round(execution_time, 1)) + " seconds")
