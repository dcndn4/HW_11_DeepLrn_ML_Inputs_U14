{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub\n"
     ]
    }
   ],
   "source": [
    "# 7:15 PM\n",
    "# 7:30 PM\n",
    "import os; print(os.path.dirname(os.getcwd()).split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>@@@</font>\n",
    "\n",
    "The RNN cheatsheet: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
    "\n",
    "<font color='red'>@@@</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since these models can be slow to train, we shall use a timer to monitor expected runtime. This might be lowerbound since my desktop CPU is fairly fast.\n",
    "import time  # for stopwatch and sleep\n",
    "t1 = time.perf_counter()  # track execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Do: RNNs for NLP - Sentiment Analysis\n",
    "\n",
    "In this activity, students will learn how to define a LSTM RNN model for sentiment analysis using Keras. Also, data preparation for using LSTM models for natural language processing is introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "The provided data file contains `6878` customer reviews of Coffee Shops in Austin, Texas. The reviews were taken from Yelp; however, the names of the Coffee Shops were anonymized for privacy reasons.\n",
    "\n",
    "The dataset has the following columns:\n",
    "\n",
    "* `coffee_shop_name`: The anonymized name of the coffee shop.\n",
    "\n",
    "* `full_review_text`: The customer reviews.\n",
    "\n",
    "* `sentiment`: The sentiment of each customer's review. `0` - Negative, `1` - Positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_shop_name</th>\n",
       "      <th>full_review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coffee Shop 66</td>\n",
       "      <td>Love love loved the atmosphere! Every corner o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coffee Shop 66</td>\n",
       "      <td>Listed in Date Night: Austin, Ambiance in Aust...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coffee Shop 66</td>\n",
       "      <td>Listed in Brunch Spots I loved the eclectic an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coffee Shop 66</td>\n",
       "      <td>Very cool decor! Good drinks Nice seating  How...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coffee Shop 66</td>\n",
       "      <td>They are located within the Northcross mall sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coffee_shop_name                                   full_review_text  \\\n",
       "0   Coffee Shop 66  Love love loved the atmosphere! Every corner o...   \n",
       "1   Coffee Shop 66  Listed in Date Night: Austin, Ambiance in Aust...   \n",
       "2   Coffee Shop 66  Listed in Brunch Spots I loved the eclectic an...   \n",
       "3   Coffee Shop 66  Very cool decor! Good drinks Nice seating  How...   \n",
       "4   Coffee Shop 66  They are located within the Northcross mall sh...   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "filepath=\"C:/Users/CS_Knit_tinK_SC/Documents/My Data Sources/121621/02_austin_coffee_shops_reviews.csv\"\n",
    "#file_path = Path(\"../Resources/austin_coffee_shops_reviews.csv\")\n",
    "reviews_df = pd.read_csv(filepath)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "RNN input requires an array data type. The `full_review_text` column will be transformed into the `X` array and the “sentiment” column into the `y` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the X and y vectors\n",
    "X = reviews_df[\"full_review_text\"].values\n",
    "y = reviews_df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the RNN model, we need to encode the text data as an integer. This transformation can be done using the following tools from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>@@@</font>\n",
    "\n",
    "Importing some new libraries!\n",
    "\n",
    "Keras contains many preprocessing modules: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\n",
    "\n",
    "Here, we use 2 of them...\n",
    "\n",
    "> Padding is a special form of masking where the masked steps are at the start or the end of a sequence. Padding comes from the need to encode sequence data into contiguous batches: in order to make all sequences in a batch fit a given standard length, it is necessary to pad or truncate some sequences.\n",
    ">\n",
    "> `raw_inputs = [[711, 632, 71],\n",
    "    [73, 8, 3215, 55, 927],\n",
    "    [83, 91, 1, 645, 1253, 927],\n",
    "]`\n",
    ">\n",
    "> `[[ 711  632   71    0    0    0]\n",
    " [  73    8 3215   55  927    0]\n",
    " [  83   91    1  645 1253  927]]`\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/masking_and_padding\n",
    "\n",
    "Tokenizer: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "\n",
    "<font color='red'>@@@</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for data encoding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>@@@</font>\n",
    "\n",
    "Tokenizer creates a key-value pair of `word1: 01`, where the latter is merely an assigned integer.\n",
    "\n",
    "<font color='red'>@@@</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: 'the', token: 1\n",
      "word: 'and', token: 2\n",
      "word: 'a', token: 3\n",
      "word: 'i', token: 4\n",
      "word: 'to', token: 5\n"
     ]
    }
   ],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "for token in list(tokenizer.word_index)[:5]:\n",
    "    print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>@@@</font>\n",
    "\n",
    "We transform every review into numerical sequences.\n",
    "\n",
    "<font color='red'>@@@</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text comment**\n",
      "{'Love love loved the atmosphere! Every corner of the coffee shop had its own style, and there were swings!!! I ordered the matcha latte, and it was muy fantastico! Ordering and getting my drink were pretty streamlined. I ordered on an iPad, which included all beverage selections that ranged from coffee to wine, desired level of sweetness, and a checkout system. I got my latte within minutes!  I was hoping for a typical heart or feather on my latte, but found myself listing out all the possibilities of what the art may be. Any ideas?'}\n",
      "**Numerical sequence representation**\n",
      "[53, 53, 301, 1, 114, 188, 589, 6, 1, 8, 65, 29, 255, 351, 810, 2, 36, 50, 1138, 4, 125, 1, 511, 69, 2, 11, 10, 5621, 5019, 506, 2, 319, 16, 106, 50, 89, 4562, 4, 125, 21, 58, 1112, 68, 1909, 40, 967, 998, 18, 5020, 43, 8, 5, 416, 3656, 1018, 6, 732, 2, 3, 4563, 1289, 4, 90, 16, 69, 999, 312, 4, 10, 1364, 12, 3, 811, 652, 39, 5622, 21, 16, 69, 17, 302, 474, 4202, 38, 40, 1, 4203, 6, 71, 1, 368, 439, 31, 192, 2363]\n"
     ]
    }
   ],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Contrast a sample numerical sequence with its text version\n",
    "print(\"**Text comment**\")\n",
    "print({X[0]})\n",
    "print(\"**Numerical sequence representation**\")\n",
    "print(X_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The RNN model requires that all the values of the `X` vector have the same length; the `pad_sequences` method will ensure that all integer encoded reviews have the same size. Each entry in `X` will be shortened to `140` integers, or pad with `0's` in case it's shorter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "X_pad = pad_sequences(X_seq, maxlen=140, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is encoded, the training and testing sets will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, random_state=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN Model\n",
    "\n",
    "In this section, a custom LSTM RNN model is going to be designed in Keras, and it's going to be fitted (trained) using the training data we defined.\n",
    "\n",
    "These are the steps that will be followed:\n",
    "\n",
    "* Define the model architecture in Keras.\n",
    "\n",
    "* Compile the model.\n",
    "\n",
    "* Fit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras Modules\n",
    "\n",
    "To build an LSTM RNN model in Keras, the `Sequential` model is used; however, there are two new types of layers that are needed:\n",
    "\n",
    "* `Embeding`: It's a type of layer that is used in neural networks to process encoded text data.\n",
    "\n",
    "* `LSTM`: It's used to add an LSTM layer to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>@@@</font>\n",
    "\n",
    "Embedding: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding?version=stable\n",
    "\n",
    "LSTM: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM?version=stable\n",
    "\n",
    "<font color='red'>@@@</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Model\n",
    "\n",
    "**Read below**\n",
    "\n",
    "The `Embedding` layer requires as parameter the size of the vocabulary in the text that is going to be processed. The `vocabulary_size` is set at the total number of words in the `tokenizer` dictionary plus `1`. The other parameter needed by this layer is the `input_length`; this parameter is set at `140` (`max_words` variable) that is the value defined for padding the reviews.\n",
    "\n",
    "The `embedding_size` parameter specifies how many dimensions will be used to represent each word. As a rule-of-thumb, a multiple of eight could be used; for this demo, tuning the model value to `64` delivered the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17051"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model set-up\n",
    "vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "max_words = 140\n",
    "embedding_size = 64  # generally use multiples of 8\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "# NOTE: This layer processes the integer-encoded sequence of each review comment to create a dense vector that feeds into the next LSTM layer.\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "# NOTE: = 2x the max_words\n",
    "# LSTM transforms the dense vector into a new one that contains info about the entire sequence that will be used \n",
    "# by the activation function in the `Dense` layer to score sentiments.\n",
    "model.add(LSTM(units=280))\n",
    "\n",
    "# NOTE: Adding more LSTMs could improve performance!\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 140, 64)           1091264   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 280)               386400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 281       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,477,945\n",
      "Trainable params: 1,477,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>@@@</font>\n",
    "\n",
    "Larger batch size will speed the training time.\n",
    "\n",
    "<font color='red'>@@@</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 18s 3s/step - loss: 0.6014\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 17s 3s/step - loss: 0.3458\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 16s 3s/step - loss: 0.3390\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.3347\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.3344\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 16s 3s/step - loss: 0.3325\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.3307\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.3282\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.3227\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 16s 3s/step - loss: 0.3158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac12df4e48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sentiment predictions\n",
    "predicted = (model.predict(X_test[:10]) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>@@@</font>\n",
    "\n",
    "_ indicates a throwaway variable, I think the article said?\n",
    "\n",
    "<font color='red'>@@@</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The table below compares the actual text (not the sequences) from the original dataframe to the predicted values\n",
    "# For that purpose we need to apply train_test_split with the same random state to the original X and save it as  X_test_original (we don't need the other values)\n",
    "_, X_test_original, _, _ = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 check-ins Listed in Om Noms Austin Props to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This my second time at this great coffee shop ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I basically live in this place during semester...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A friend introduced me to Alta's last year by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think this place makes the best espresso dri...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The only place in town I would order my Cortad...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Parking is skimp, but luckily there are some s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Awesome new coffee shop in the Domain! It's a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I came by here in a party of 2 a little before...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is literally my favorite coffee shop in A...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Actual  Predicted\n",
       "0  3 check-ins Listed in Om Noms Austin Props to ...       1          1\n",
       "1  This my second time at this great coffee shop ...       1          1\n",
       "2  I basically live in this place during semester...       1          1\n",
       "3  A friend introduced me to Alta's last year by ...       1          1\n",
       "4  I think this place makes the best espresso dri...       1          1\n",
       "5  The only place in town I would order my Cortad...       1          1\n",
       "6  Parking is skimp, but luckily there are some s...       1          1\n",
       "7  Awesome new coffee shop in the Domain! It's a ...       1          1\n",
       "8  I came by here in a party of 2 a little before...       1          1\n",
       "9  This is literally my favorite coffee shop in A...       1          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "sentiments = pd.DataFrame({\"Text\": X_test_original[:10], \"Actual\": y_test[:10], \"Predicted\": predicted.ravel()})\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 165.9 seconds\n"
     ]
    }
   ],
   "source": [
    "t2 = time.perf_counter()\n",
    "execution_time = t2 - t1\n",
    "print(\"execution time: \" + str(round(execution_time, 1)) + \" seconds\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
